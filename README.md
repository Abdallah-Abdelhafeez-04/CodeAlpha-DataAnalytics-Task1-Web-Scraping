# CodeAlpha-DataAnalytics-Task1-Web-Scraping
This project demonstrates a complete web scraping workflow to extract book information from the "books.toscrape.com" website. The implementation includes data extraction, cleaning, analysis, and visualization of book data including titles, prices, availability, and ratings.

The project showcases essential skills in:

Web scraping with BeautifulSoup

Data processing with pandas

Data cleaning and transformation

Data visualization with matplotlib and seaborn

Handling pagination in web scraping

Exporting processed data

üìä Project Overview
The script scrapes book data from all 50 pages of the books.toscrape.com website, collecting information on:

Book titles

Prices

Availability status

Star ratings

Stock status (derived field)

After collection, the data is cleaned, processed, and analyzed to provide insights into the book catalog.

üõ†Ô∏è Technologies Used
Python 3

BeautifulSoup4 (Web scraping)

pandas (Data manipulation)

matplotlib & seaborn (Data visualization)

requests (HTTP requests)

lxml (HTML parsing)

üìÅ Files
CodeAlpha First Task.ipynb - Main Jupyter notebook containing the complete implementation

books_clean.csv - Processed and cleaned dataset (generated by the script)

 How to Use
Clone the repository

Install required packages: pip install requests beautifulsoup4 lxml pandas matplotlib seaborn

Open the Jupyter notebook: jupyter notebook "CodeAlpha First Task.ipynb"

Run all cells to execute the complete workflow

üìà Key Features
Complete Web Scraping: Handles pagination to scrape all 50 pages of the website

Data Cleaning: Standardizes column names, handles missing values, removes duplicates

Data Enrichment: Creates derived fields like stock status

Data Validation: Checks for missing values, duplicates, and data consistency

Visualization: Generates histograms and count plots for price distribution and rating analysis

Data Export: Saves cleaned data to CSV format

üìã Data Fields
The dataset includes the following fields:

title: Book title

price: Book price (as string with currency symbol)

availability: Stock availability text

rating: Star rating (text: One, Two, Three, Four, Five)

is_in_stock: Boolean indicating if book is in stock

üìä Sample Insights
The dataset contains 999 unique books after removing duplicates

All books in the sample were marked as "In stock"

Price distribution shows most books fall within a certain price range

Ratings are distributed across all five star categories

üîÑ Workflow
Setup and installation of required libraries

Initial scraping of a single page for testing

Implementation of pagination handling to scrape all pages

Data cleaning and transformation

Data validation and quality checks

Visualization of key metrics

Export of cleaned data

This project serves as a comprehensive example of a complete data acquisition and processing pipeline, from web scraping to cleaned, analysis-ready data.
